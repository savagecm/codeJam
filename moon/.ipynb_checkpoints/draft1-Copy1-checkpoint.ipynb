{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import log_loss, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA pre-prosessing part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load training data and lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('orange_small_train.data', sep = '\\t')\n",
    "appetency = pd.read_csv('orange_small_train_appetency_train.labels',header=None).astype('float')\n",
    "churn = pd.read_csv('orange_small_train_churn_train.labels', header=None).astype('float')\n",
    "upselling = pd.read_csv('orange_small_train_upselling_train.labels',header=None).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "appetency.columns = ['appetency']\n",
    "churn.columns = ['churn']\n",
    "upselling.columns = ['upselling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {'-1':[-1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#appetency[appetency.appetency ==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('orange_small_test.data', sep = '\\t')\n",
    "test_appetency = pd.read_csv('orange_small_train_appetency_test.labels',header=None).astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a look at the head 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>...</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "      <th>Var230</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>fXVEsaq</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xb3V</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>525.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>2Kb5FSF</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5236.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Al6ZaUT</td>\n",
       "      <td>NKv4yOc</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>Qu4f</td>\n",
       "      <td>02N6s8f</td>\n",
       "      <td>ib5G6X1eUxUn6</td>\n",
       "      <td>am7c</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>CE7uk3u</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>1J2cvxe</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>658.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>zCkv</td>\n",
       "      <td>QqVuch3</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Qcbd</td>\n",
       "      <td>02N6s8f</td>\n",
       "      <td>Zy3gnGM</td>\n",
       "      <td>am7c</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>XlgxB9z</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "      <td>am7c</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>R2LdzOv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>zCkv</td>\n",
       "      <td>K2SqEo9</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>PM2D</td>\n",
       "      <td>6fzt</td>\n",
       "      <td>am14IcfM7tWLrUmRT52KtA</td>\n",
       "      <td>am7c</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>EPqQcw6</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var1  Var2  Var3  Var4  Var5    Var6  Var7  Var8  Var9  Var10  ...  \\\n",
       "0   NaN   NaN   NaN   NaN   NaN  1526.0   7.0   NaN   NaN    NaN  ...   \n",
       "1   NaN   NaN   NaN   NaN   NaN   525.0   0.0   NaN   NaN    NaN  ...   \n",
       "2   NaN   NaN   NaN   NaN   NaN  5236.0   7.0   NaN   NaN    NaN  ...   \n",
       "3   NaN   NaN   NaN   NaN   NaN     NaN   0.0   NaN   NaN    NaN  ...   \n",
       "4   NaN   NaN   NaN   NaN   NaN  1029.0   7.0   NaN   NaN    NaN  ...   \n",
       "5   NaN   NaN   NaN   NaN   NaN   658.0   7.0   NaN   NaN    NaN  ...   \n",
       "6   NaN   NaN   NaN   NaN   NaN  1680.0   7.0   NaN   NaN    NaN  ...   \n",
       "7   NaN   NaN   NaN   NaN   NaN    77.0   0.0   NaN   NaN    NaN  ...   \n",
       "8   NaN   NaN   NaN   NaN   NaN  1176.0   7.0   NaN   NaN    NaN  ...   \n",
       "9   NaN   NaN   NaN   NaN   NaN  1141.0   7.0   NaN   NaN    NaN  ...   \n",
       "\n",
       "    Var221   Var222      Var223  Var224  Var225  Var226   Var227  \\\n",
       "0     oslk  fXVEsaq  jySVZNlOJy     NaN     NaN    xb3V     RAYp   \n",
       "1     oslk  2Kb5FSF  LM8l689qOp     NaN     NaN    fKCe     RAYp   \n",
       "2  Al6ZaUT  NKv4yOc  jySVZNlOJy     NaN    kG3k    Qu4f  02N6s8f   \n",
       "3     oslk  CE7uk3u  LM8l689qOp     NaN     NaN    FSa2     RAYp   \n",
       "4     oslk  1J2cvxe  LM8l689qOp     NaN    kG3k    FSa2     RAYp   \n",
       "5     zCkv  QqVuch3  LM8l689qOp     NaN     NaN    Qcbd  02N6s8f   \n",
       "6     oslk  XlgxB9z  LM8l689qOp     NaN    kG3k    FSa2     RAYp   \n",
       "7     oslk  R2LdzOv         NaN     NaN     NaN    FSa2     RAYp   \n",
       "8     zCkv  K2SqEo9  jySVZNlOJy     NaN    kG3k    PM2D     6fzt   \n",
       "9     oslk  EPqQcw6  LM8l689qOp     NaN    kG3k    FSa2     RAYp   \n",
       "\n",
       "                   Var228  Var229  Var230  \n",
       "0           F2FyR07IdsN7I     NaN     NaN  \n",
       "1           F2FyR07IdsN7I     NaN     NaN  \n",
       "2           ib5G6X1eUxUn6    am7c     NaN  \n",
       "3           F2FyR07IdsN7I     NaN     NaN  \n",
       "4           F2FyR07IdsN7I    mj86     NaN  \n",
       "5                 Zy3gnGM    am7c     NaN  \n",
       "6                 55YFVY9    am7c     NaN  \n",
       "7           F2FyR07IdsN7I     NaN     NaN  \n",
       "8  am14IcfM7tWLrUmRT52KtA    am7c     NaN  \n",
       "9                 55YFVY9     NaN     NaN  \n",
       "\n",
       "[10 rows x 230 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if there are too many missing data, draw the loss data picture here TO BE DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_names = train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Var1', 'Var2', 'Var3', 'Var4', 'Var5', 'Var6', 'Var7', 'Var8', 'Var9',\n",
       "       'Var10',\n",
       "       ...\n",
       "       'Var221', 'Var222', 'Var223', 'Var224', 'Var225', 'Var226', 'Var227',\n",
       "       'Var228', 'Var229', 'Var230'],\n",
       "      dtype='object', length=230)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####create an 25000 dimentions with 0 array = [0]*250000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###arrayportion_series = pd.Series(0,index = train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###train_data.index train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the columns whose loss rate > 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop_list = [x for x in column_names if len([ y for y in train_data.loc[:,x].isna() if y == True]) > train_data.shape[0]*0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#drop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##train_data.shape??? To judge if data is data frame or series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#####\n",
    "for x in column_names:\n",
    "    test_arr = []\n",
    "    for y in train_data.loc[:,x].isna() :\n",
    "        if y == False :\n",
    "            test_arr.append(y)\n",
    "    #print(\"lable =\"+x)\n",
    "   # print(len(test_arr))\n",
    "   # print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(drop_list,axis=1)\n",
    "#test_data = test_data.drop(drop_list,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill the NA of the data type is  int or float data with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_data.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can see from above that only numberic columns are printed, so just use below function to fill the na numberic values.\n",
    "#### Tree models do not need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data.fillna(train_data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data.dtypes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the string columns to category type. Need an analysis figure to illustrate why category can be chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "object_columns = train_data.select_dtypes(['object']).columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data[object_columns] = train_data[object_columns].apply(lambda col: col.astype('category'))\n",
    "#test_data[object_columns] = test_data[object_columns].apply(lambda col: col.astype('category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data['Var223'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(train_data.select_dtypes(['category']).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the category to codes. Not needed for tree models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data[object_columns] = train_data[object_columns].apply(lambda x: x.cat.codes)\n",
    "#test_data[object_columns] = test_data[object_columns].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the category type to float. Not needed for tree models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_data[object_columns] = train_data[object_columns].apply(lambda x: x.astype('int'))\n",
    "#test_data[object_columns] = test_data[object_columns].apply(lambda x: x.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rebalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(1)                # the first figure\n",
    "plt.subplot(121)             # the first subplot in the first figure\n",
    "plt.plot([1, 2, 3])\n",
    "plt.subplot(122)             # the second subplot in the first figure\n",
    "plt.plot([4, 5, 6])\n",
    "  \n",
    "\n",
    "\n",
    "plt.title('Easy as 1, 2, 3') # subplot 211 title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.concat([appetency, churn, upselling],axis=1)\n",
    "labels.columns = ['appetency', 'churn', 'upselling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax0 = appetency.hist(bins=4)\n",
    "#print(ax0)\n",
    "#ax0[0][0].set_ylabel(\"Appetency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appetency = (appetency + 1)/2\n",
    "churn = (churn + 1)/2\n",
    "upselling = (upselling + 1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train_data,appetency],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##appetency.columns = ['col1']\n",
    "#churn.columns = ['col1']\n",
    "#upselling.columns = ['col1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax0 = appetency.hist(bins=4)\n",
    "len(appetency[appetency.appetency == 0])\n",
    "len(appetency[appetency.appetency == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1,figsize=(15,6))\n",
    "plt.subplot(131)\n",
    "plt.title(\"appetency\")\n",
    "plt.bar([0,1],[len(appetency[appetency.appetency <= 0]),len(appetency[appetency.appetency > 0])])\n",
    "plt.subplot(132)\n",
    "plt.title(\"churn\")\n",
    "plt.bar([0,1],[len(appetency[churn.churn <= 0]),len(appetency[churn.churn > 0])])\n",
    "plt.subplot(133)\n",
    "plt.title(\"upselling\")\n",
    "plt.bar([0,1],[len(appetency[upselling.upselling <= 0]),len(appetency[upselling.upselling > 0])])\n",
    "#ax1= churn.hist(bins=4)\n",
    "#ax1.ylabel('{}'.format('Churn'))               \n",
    "\n",
    "#plt.subplot(132)\n",
    "#ax2= upselling.hist(bins=4)\n",
    "#ax2.ylabel('{}'.format('Upselling'))\n",
    "\n",
    "#plt.subplot(133,label=\"app\")\n",
    "#ax0 = appetency.hist(bins=4)\n",
    "#ax0[0][0].set_ylabel('{}'.format('Appetency'))\n",
    "\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "#datatrain = data.drop(['churn','upselling'],axis=1)\n",
    "df_maj = data[data.appetency==0]\n",
    "df_min = data[data.appetency==1]\n",
    "df_maj.shape,df_min.shape \n",
    "# Upsample minority class\n",
    "df_min_upsampled = resample(df_min, \n",
    "                                replace=True,     # sample with replacement\n",
    "                                 n_samples=df_maj.shape[0],    # to match majority class\n",
    "                                 random_state=RANDOM_SEED) # reproducible results\n",
    "\n",
    "df_upsampled = pd.concat([df_maj, df_min_upsampled])\n",
    "df_X = df_upsampled.drop(['appetency'],axis=1)\n",
    "df_y = df_upsampled['appetency']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X,df_y ,test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train\n",
    "y_test = y_test\n",
    "\n",
    "X_train = preprocessing.scale(X_train)\n",
    "X_test = preprocessing.scale(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill the NA with the most frequent item TO BE DONE for non-tree classifier.\n",
    "#### Tree models do not need.\n",
    "#### Do one hot encoding. TO BE DONE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGB part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### lgb load training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lgb_train_data = lgb.Dataset(data=train_data, label=appetency)\n",
    "#lgb_test_data = lgb.Dataset(data=test_data,label=test_appetency,reference=lgb_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####lgb parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#param = {'num_leaves': 31, 'objective': 'binary','metric':'auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####Training lgb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for ty in train_data.dtypes:\n",
    "    #print(ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#num_round = 10\n",
    "#bst = lgb.train(param, lgb_train_data, num_round, valid_sets=[lgb_test_data])#,categorical_feature=object_columns, valid_sets=[lgb_test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pred = bst.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appetency.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appetency[appetency.col1 == 1].shape[0]/appetency.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 3, 5,  6, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appetency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(train_data, appetency, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " gbm = lgb.LGBMClassifier(n_estimators=50, silent=True)\n",
    " gbm.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=5, verbose=False)\n",
    " #result = gbm.predict_proba(X_test)\n",
    " #print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = gbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len([x for x in result2 if x == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#y_train.describe()\n",
    "y_test.describe()\n",
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in y_train if x != -1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " ret = log_loss(y_test, gbm.predict_proba(X_test))\n",
    " print(ret)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
