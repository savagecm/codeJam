{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import log_loss, mean_squared_error, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from category_encoders import BinaryEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DATA pre-prosessing part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1.1    Load training data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('orange_small_train.data', sep = '\\t')\n",
    "appetency = pd.read_csv('orange_small_train_appetency_train.labels',header=None).astype('float')\n",
    "churn = pd.read_csv('orange_small_train_churn_train.labels', header=None).astype('float')\n",
    "upselling = pd.read_csv('orange_small_train_upselling_train.labels',header=None).astype('float')\n",
    "\n",
    "appetency.columns = ['appetency']\n",
    "churn.columns = ['churn']\n",
    "upselling.columns = ['upselling']\n",
    "churn = (churn + 1)/2\n",
    "upselling = (upselling + 1)/2\n",
    "appetency = (appetency + 1)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2     Dictionary to save the info used by test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info_dic={}\n",
    "train_info_dic['orig_columns']=train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Drop the columns all with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_names = train_data.columns #all rows has at least one feature...\n",
    "drop_list = [x for x in column_names if len([ y for y in train_data.loc[:,x].isna() if y == True]) == train_data.shape[0]]\n",
    "train_data_drop_na = train_data.drop(drop_list,axis=1)\n",
    "train_info_dic['drop_list'] = drop_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Convert object --> category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_columns = train_data_drop_na.select_dtypes(['object']).columns\n",
    "train_data_drop_na[category_columns] = train_data_drop_na[category_columns].apply(lambda col: col.astype('category'))\n",
    "numberic_columns = train_data_drop_na.select_dtypes(exclude=['category']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 For numberic columns whose categories num less than 5, treat it as category type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_categorical=[]\n",
    "for col in numberic_columns:\n",
    "    if len(train_data_drop_na[col].value_counts().to_dict()) < 5:\n",
    "        num_to_categorical.append(col)\n",
    "train_info_dic['num_to_categorical'] = num_to_categorical\n",
    "train_data_drna_nu2ca = train_data_drop_na.copy()\n",
    "train_data_drna_nu2ca[num_to_categorical]=train_data_drop_na[num_to_categorical].apply(lambda col: col.astype('category'))\n",
    "category_columns_list = category_columns.tolist()\n",
    "numberic_columns_list = numberic_columns.tolist()\n",
    "category_columns_list += num_to_categorical\n",
    "numberic_columns_list = [col for col in numberic_columns_list if col not in num_to_categorical]\n",
    "train_info_dic['category_columns'] = category_columns_list\n",
    "train_info_dic['numberic_columns'] = numberic_columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### impute data with the nearest ones, not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport numpy as np\\nfrom sklearn.experimental import enable_iterative_imputer\\nfrom sklearn.impute import IterativeImputer\\nimp = IterativeImputer(max_iter=5, random_state=0)\\nimp.fit(train_data_drop_na[numberic_columns])  \\ntrain_data_drop_na_imputed = imp.transform(train_data_drop_na[numberic_columns])\\ntrain_data_drop_na[numberic_columns] = pd.DataFrame(train_data_drop_na_imputed)\\ntrain_data_drna_mean = train_data_drop_na\\ntrain_info_dic['imp'] = imp\\n\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(max_iter=5, random_state=0)\n",
    "imp.fit(train_data_drop_na[numberic_columns])  \n",
    "train_data_drop_na_imputed = imp.transform(train_data_drop_na[numberic_columns])\n",
    "train_data_drop_na[numberic_columns] = pd.DataFrame(train_data_drop_na_imputed)\n",
    "train_data_drna_mean = train_data_drop_na\n",
    "train_info_dic['imp'] = imp\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Handle numberic value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 fill with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data_drna_nu2ca_mean = train_data_drna_nu2ca\n",
    "train_data_drna_nu2ca_mean[numberic_columns_list] = train_data_drna_nu2ca[numberic_columns_list].fillna(train_data_drna_nu2ca[numberic_columns_list].mean())\n",
    "train_info_dic['train_data_mean'] = train_data_drna_nu2ca[numberic_columns_list].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_data_drna_nu2ca_mean_scale = train_data_drna_nu2ca_mean\n",
    "std_scaler = preprocessing.StandardScaler().fit(train_data_drna_nu2ca_mean[numberic_columns_list])\n",
    "train_data_drna_nu2ca_mean_scale[numberic_columns_list] = std_scaler.transform(train_data_drna_nu2ca_mean[numberic_columns_list])\n",
    "train_info_dic['std_scaler'] = std_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Handle category columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.5.1 Binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_encoder = BinaryEncoder(cols=category_columns_list)\n",
    "train_data_drna_nu2ca_mean_scale_bin  = binary_encoder.fit_transform(train_data_drna_nu2ca_mean_scale)\n",
    "train_info_dic['binary_encoder'] = binary_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 Save training info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_info_dic.pkl','wb') as f:\n",
    "    pickle.dump(train_info_dic,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8  Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig = plt.figure(1,figsize=(15,6))\n",
    "plt.subplot(131)\n",
    "plt.title(\"appetency\")\n",
    "plt.bar([0,1],[len(appetency[appetency.appetency <= 0]),len(appetency[appetency.appetency > 0])])\n",
    "plt.subplot(132)\n",
    "plt.title(\"churn\")\n",
    "plt.bar([0,1],[len(appetency[churn.churn <= 0]),len(appetency[churn.churn > 0])])\n",
    "plt.subplot(133)\n",
    "plt.title(\"upselling\")\n",
    "plt.bar([0,1],[len(appetency[upselling.upselling <= 0]),len(appetency[upselling.upselling > 0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Random Up sampling , not good\n",
    "##### SMOTE, not good\n",
    "##### Choose random downsampling\n",
    "\n",
    "RANDOM_SEED = 320\n",
    "train_data_drna_nu2ca_mean_scale_bin_pd = pd.DataFrame(train_data_drna_nu2ca_mean_scale_bin)\n",
    "processed_train_data_with_appetency = pd.concat([train_data_drna_nu2ca_mean_scale_bin_pd,appetency],axis=1)\n",
    "df_maj_with_appetency = processed_train_data_with_appetency[processed_train_data_with_appetency.appetency==0]\n",
    "df_min_with_appetency = processed_train_data_with_appetency[processed_train_data_with_appetency.appetency==1]\n",
    "df_maj_downsampled_appetency = resample(df_maj_with_appetency, replace=True, n_samples=df_min_with_appetency .shape[0]*10, random_state=RANDOM_SEED) # reproducible resultsRANDOM_SEED\n",
    "df_downsampled_appetency = pd.concat([df_min_with_appetency, df_maj_downsampled_appetency])\n",
    "df_downsampled_shuffled_appetency =shuffle(df_downsampled_appetency)\n",
    "df_X_appetency = df_downsampled_shuffled_appetency.drop(['appetency'],axis=1)\n",
    "df_y_appetency = df_downsampled_shuffled_appetency['appetency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data_drna_nu2ca_mean_scale_bin_pd = pd.DataFrame(train_data_drna_nu2ca_mean_scale_bin)\n",
    "processed_train_data_with_churn = pd.concat([train_data_drna_nu2ca_mean_scale_bin_pd,churn],axis=1)\n",
    "df_maj_with_churn = processed_train_data_with_churn[processed_train_data_with_churn.churn==0]\n",
    "df_min_with_churn = processed_train_data_with_churn[processed_train_data_with_churn.churn==1]\n",
    "df_maj_downsampled_churn = resample(df_maj_with_churn, replace=True, n_samples=df_min_with_churn .shape[0]*10, random_state=RANDOM_SEED) # reproducible resultsRANDOM_SEED\n",
    "df_downsampled_churn = pd.concat([df_min_with_churn, df_maj_downsampled_churn])\n",
    "df_downsampled_shuffled_churn =shuffle(df_downsampled_churn)\n",
    "df_X_churn = df_downsampled_shuffled_churn.drop(['churn'],axis=1)\n",
    "df_y_churn = df_downsampled_shuffled_churn['churn']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data_drna_nu2ca_mean_scale_bin_pd = pd.DataFrame(train_data_drna_nu2ca_mean_scale_bin)\n",
    "processed_train_data_with_upselling = pd.concat([train_data_drna_nu2ca_mean_scale_bin_pd,upselling],axis=1)\n",
    "df_maj_with_upselling = processed_train_data_with_upselling[processed_train_data_with_upselling.upselling==0]\n",
    "df_min_with_upselling = processed_train_data_with_upselling[processed_train_data_with_upselling.upselling==1]\n",
    "df_maj_downsampled_upselling = resample(df_maj_with_upselling, replace=True, n_samples=df_min_with_upselling .shape[0]*10, random_state=RANDOM_SEED) # reproducible resultsRANDOM_SEED\n",
    "df_downsampled_upselling = pd.concat([df_min_with_upselling, df_maj_downsampled_upselling])\n",
    "df_downsampled_shuffled_upselling =shuffle(df_downsampled_upselling)\n",
    "df_X_upselling = df_downsampled_shuffled_upselling.drop(['upselling'],axis=1)\n",
    "df_y_upselling = df_downsampled_shuffled_upselling['upselling']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample for lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Var191', 'Var192', 'Var193', 'Var194', 'Var195', 'Var196', 'Var197',\n",
       "       'Var198', 'Var199', 'Var200', 'Var201', 'Var202', 'Var203', 'Var204',\n",
       "       'Var205', 'Var206', 'Var207', 'Var208', 'Var210', 'Var211', 'Var212',\n",
       "       'Var213', 'Var214', 'Var215', 'Var216', 'Var217', 'Var218', 'Var219',\n",
       "       'Var220', 'Var221', 'Var222', 'Var223', 'Var224', 'Var225', 'Var226',\n",
       "       'Var227', 'Var228', 'Var229'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_drop_na.select_dtypes(['category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_drop_na_pd = pd.DataFrame(train_data_drop_na)\n",
    "processed_train_data_lightgbm_with_appetency = pd.concat([train_data_drop_na_pd,appetency],axis=1)\n",
    "df_maj_lightgbm_with_appetency = processed_train_data_lightgbm_with_appetency[processed_train_data_lightgbm_with_appetency.appetency==0]\n",
    "df_min_lightgbm_with_appetency = processed_train_data_lightgbm_with_appetency[processed_train_data_lightgbm_with_appetency.appetency==1]\n",
    "df_maj_lightgbm_downsampled_appetency = resample(df_maj_lightgbm_with_appetency, replace=True, n_samples=df_min_lightgbm_with_appetency .shape[0]*10, random_state=RANDOM_SEED) # reproducible resultsRANDOM_SEED\n",
    "df_downsampled_lightgbm_appetency = pd.concat([df_min_lightgbm_with_appetency, df_maj_lightgbm_downsampled_appetency])\n",
    "df_downsampled_lightgbm_shuffled_appetency =shuffle(df_downsampled_lightgbm_appetency)\n",
    "df_X_lightgbm_appetency = df_downsampled_lightgbm_shuffled_appetency.drop(['appetency'],axis=1)\n",
    "df_y_lightgbm_appetency = df_downsampled_lightgbm_shuffled_appetency['appetency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_drop_na_pd = pd.DataFrame(train_data_drop_na)\n",
    "processed_train_data_lightgbm_with_churn = pd.concat([train_data_drop_na_pd,churn],axis=1)\n",
    "df_maj_lightgbm_with_churn = processed_train_data_lightgbm_with_churn[processed_train_data_lightgbm_with_churn.churn==0]\n",
    "df_min_lightgbm_with_churn = processed_train_data_lightgbm_with_churn[processed_train_data_lightgbm_with_churn.churn==1]\n",
    "df_maj_lightgbm_downsampled_churn = resample(df_maj_lightgbm_with_churn, replace=True, n_samples=df_min_lightgbm_with_churn .shape[0]*5, random_state=RANDOM_SEED) # reproducible resultsRANDOM_SEED\n",
    "df_downsampled_lightgbm_churn = pd.concat([df_min_lightgbm_with_churn, df_maj_lightgbm_downsampled_churn])\n",
    "df_downsampled_lightgbm_shuffled_churn =shuffle(df_downsampled_lightgbm_churn)\n",
    "df_X_lightgbm_churn = df_downsampled_lightgbm_shuffled_churn.drop(['churn'],axis=1)\n",
    "df_y_lightgbm_churn = df_downsampled_lightgbm_shuffled_churn['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_drop_na_pd = pd.DataFrame(train_data_drop_na)\n",
    "processed_train_data_lightgbm_with_upselling = pd.concat([train_data_drop_na_pd,upselling],axis=1)\n",
    "df_maj_lightgbm_with_upselling = processed_train_data_lightgbm_with_upselling[processed_train_data_lightgbm_with_upselling.upselling==0]\n",
    "df_min_lightgbm_with_upselling = processed_train_data_lightgbm_with_upselling[processed_train_data_lightgbm_with_upselling.upselling==1]\n",
    "df_maj_lightgbm_downsampled_upselling = resample(df_maj_lightgbm_with_upselling, replace=True, n_samples=df_min_lightgbm_with_upselling .shape[0]*10, random_state=RANDOM_SEED) # reproducible resultsRANDOM_SEED\n",
    "df_downsampled_lightgbm_upselling = pd.concat([df_min_lightgbm_with_upselling, df_maj_lightgbm_downsampled_upselling])\n",
    "df_downsampled_lightgbm_shuffled_upselling =shuffle(df_downsampled_lightgbm_upselling)\n",
    "df_X_lightgbm_upselling = df_downsampled_lightgbm_shuffled_upselling.drop(['upselling'],axis=1)\n",
    "df_y_lightgbm_upselling = df_downsampled_lightgbm_shuffled_upselling['upselling']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Model training part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.1 Grid search to get the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nparam_test1 = {'n_estimators':range(10,20,2)}\\ngsearch1 = GridSearchCV(estimator = RandomForestClassifier(min_samples_split=100,\\n                         min_samples_leaf=40,max_depth=10,max_features='sqrt',\\n                        random_state=10,class_weight='balanced_subsample'), \\n                        param_grid = param_test1, scoring='roc_auc',cv=5,n_jobs=8)\\ngsearch1.fit(df_X,df_y)\\ngsearch1.best_params_, gsearch1.best_score_ \\nbest_n_estimators = gsearch1.best_params_['n_estimators']\\n\\n\\n\\nparam_test2 = {'max_depth':range(3,8,1), 'min_samples_split':range(50,110,20)} #range(50,110,20\\ngsearch2 = GridSearchCV(estimator = RandomForestClassifier(n_estimators= best_n_estimators, \\n                                 min_samples_leaf=30,max_features='sqrt',random_state=10,class_weight='balanced_subsample'),\\nparam_grid = param_test2, scoring='roc_auc',iid=False, cv=5,n_jobs=8)\\ngsearch2.fit(df_X,df_y)\\nbest_max_depth = gsearch2.best_params_['max_depth']\\n\\n\\n\\nparam_test3 = {'min_samples_split':range(80,150,20), 'min_samples_leaf':range(10,60,10)}\\ngsearch3 = GridSearchCV(estimator = RandomForestClassifier(n_estimators= best_n_estimators, max_depth=best_max_depth,\\n                                  max_features='sqrt' ,oob_score=True, random_state=10,class_weight='balanced_subsample'),\\n                                   param_grid = param_test3, scoring='roc_auc',iid=False, cv=5)\\ngsearch3.fit(df_X,df_y)\\nbest_min_samples_leaf = gsearch3.best_params_['min_samples_leaf']\\nbest_min_samples_split = gsearch3.best_params_['min_samples_split']\\n\\n\\n\\nparam_test4 = {'max_features':range(7,15,2)}\\ngsearch4 = GridSearchCV(estimator = RandomForestClassifier(n_estimators= best_n_estimators, max_depth=best_max_depth, min_samples_split= best_min_samples_split,\\n                                  min_samples_leaf=best_min_samples_leaf ,oob_score=True, random_state=10,class_weight='balanced_subsample'), param_grid = param_test4, scoring='roc_auc',iid=False, cv=5,n_jobs=8)\\ngsearch4.fit(df_X,df_y)\\nbest_max_features = gsearch4.best_params_['max_features']\\n\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "param_test1 = {'n_estimators':range(10,20,2)}\n",
    "gsearch1 = GridSearchCV(estimator = RandomForestClassifier(min_samples_split=100,\n",
    "                         min_samples_leaf=40,max_depth=10,max_features='sqrt',\n",
    "                        random_state=10,class_weight='balanced_subsample'), \n",
    "                        param_grid = param_test1, scoring='roc_auc',cv=5,n_jobs=8)\n",
    "gsearch1.fit(df_X,df_y)\n",
    "gsearch1.best_params_, gsearch1.best_score_ \n",
    "best_n_estimators = gsearch1.best_params_['n_estimators']\n",
    "\n",
    "\n",
    "\n",
    "param_test2 = {'max_depth':range(3,8,1), 'min_samples_split':range(50,110,20)} #range(50,110,20\n",
    "gsearch2 = GridSearchCV(estimator = RandomForestClassifier(n_estimators= best_n_estimators, \n",
    "                                 min_samples_leaf=30,max_features='sqrt',random_state=10,class_weight='balanced_subsample'),\n",
    "param_grid = param_test2, scoring='roc_auc',iid=False, cv=5,n_jobs=8)\n",
    "gsearch2.fit(df_X,df_y)\n",
    "best_max_depth = gsearch2.best_params_['max_depth']\n",
    "\n",
    "\n",
    "\n",
    "param_test3 = {'min_samples_split':range(80,150,20), 'min_samples_leaf':range(10,60,10)}\n",
    "gsearch3 = GridSearchCV(estimator = RandomForestClassifier(n_estimators= best_n_estimators, max_depth=best_max_depth,\n",
    "                                  max_features='sqrt' ,oob_score=True, random_state=10,class_weight='balanced_subsample'),\n",
    "                                   param_grid = param_test3, scoring='roc_auc',iid=False, cv=5)\n",
    "gsearch3.fit(df_X,df_y)\n",
    "best_min_samples_leaf = gsearch3.best_params_['min_samples_leaf']\n",
    "best_min_samples_split = gsearch3.best_params_['min_samples_split']\n",
    "\n",
    "\n",
    "\n",
    "param_test4 = {'max_features':range(7,15,2)}\n",
    "gsearch4 = GridSearchCV(estimator = RandomForestClassifier(n_estimators= best_n_estimators, max_depth=best_max_depth, min_samples_split= best_min_samples_split,\n",
    "                                  min_samples_leaf=best_min_samples_leaf ,oob_score=True, random_state=10,class_weight='balanced_subsample'), param_grid = param_test4, scoring='roc_auc',iid=False, cv=5,n_jobs=8)\n",
    "gsearch4.fit(df_X,df_y)\n",
    "best_max_features = gsearch4.best_params_['max_features']\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2  train RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel_rf = RandomForestClassifier(n_estimators= best_n_estimators, max_depth=best_max_depth, min_samples_split= 90,\\n                                  min_samples_leaf=best_min_samples_leaf, max_features =best_max_features, random_state=10, class_weight=\\'balanced_subsample\\')#class_weight=\\'balanced\\')\\nmodel_rf.fit(df_X_appetency,df_y)\\njoblib.dump(model_rf,\"random_forest.model\")\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model_rf = RandomForestClassifier(n_estimators= best_n_estimators, max_depth=best_max_depth, min_samples_split= 90,\n",
    "                                  min_samples_leaf=best_min_samples_leaf, max_features =best_max_features, random_state=10, class_weight='balanced_subsample')#class_weight='balanced')\n",
    "model_rf.fit(df_X_appetency,df_y)\n",
    "joblib.dump(model_rf,\"random_forest.model\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_appetency.model']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=600,class_weight='balanced',max_depth = 30, max_features = 0.3 ,min_samples_split=10, min_samples_leaf=5,n_jobs=8)\n",
    "model_rf.fit(df_X_appetency,df_y_appetency)\n",
    "joblib.dump(model_rf,\"random_forest_appetency.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_churn.model']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=600,class_weight='balanced',max_depth = 9, max_features = 0.3 ,min_samples_split=10,min_samples_leaf=5,n_jobs=8)\n",
    "model_rf.fit(df_X_churn,df_y_churn)\n",
    "joblib.dump(model_rf,\"random_forest_churn.model\") ##max depth 9 10 11,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=600,class_weight='balanced',max_depth = 30, max_features = 0.3 ,min_samples_split=10,min_samples_leaf=5,n_jobs=8)\n",
    "model_rf.fit(df_X_upselling,df_y_upselling)\n",
    "joblib.dump(model_rf,\"random_forest_upselling.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.1 Grid search to get the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nparams_test1={'max_depth': range(3,10,1), 'num_leaves':range(5, 100, 5)}\\ngsearch1 = GridSearchCV(estimator=model_lgb, param_grid=params_test1, scoring='roc_auc', cv=5, verbose=1, n_jobs=8)\\ngsearch1.fit(df_X, df_y)\\nbest_max_depth = gsearch1.best_params_['max_depth']\\nbest_num_leaves = gsearch1.best_params_['num_leaves']\\n\\n\\nmodel_lgb = lgb.LGBMClassifier(n_estimators=30,\\n                               silent=True,\\n                               max_bin=50,\\n                               learning_rate=0.1,\\n                               num_leaves=best_num_leaves,\\n                               min_data_in_leaf=20,\\n                               feature_fraction=1.0,\\n                               max_depth=best_max_depth)\\n\\nparams_test2={'max_bin': range(5,255,5), 'min_data_in_leaf':range(10, 200, 5)}\\ngsearch2 = GridSearchCV(estimator=model_lgb, param_grid=params_test2, scoring='roc_auc', cv=5, verbose=1, n_jobs=8)\\ngsearch2.fit(df_X, df_y)\\nbest_max_bin = gsearch2.best_params_['max_bin']\\nbest_min_data_in_leaf = gsearch2.best_params_['min_data_in_leaf']\\n\\n\\n\\nmodel_lgb = lgb.LGBMClassifier(n_estimators=30,\\n                               silent=True,\\n                               max_bin=best_max_bin,\\n                               learning_rate=0.1,\\n                               num_leaves=best_num_leaves,\\n                               min_data_in_leaf=best_min_data_in_leaf,\\n                               feature_fraction=1.0,\\n                               max_depth=best_max_depth)\\n\\nparams_test3={'feature_fraction': [0.5, 0.6, 0.7, 0.8, 0.9,1.0], 'bagging_fraction': [0.6, 0.7, 0.8, 0.9, 1.0]}\\ngsearch3 = GridSearchCV(estimator=model_lgb, param_grid=params_test3, scoring='roc_auc', cv=5, verbose=1, n_jobs=8)\\ngsearch3.fit(df_X, df_y)\\nbest_bagging_fraction = gsearch3.best_params_['bagging_fraction']\\nbest_feature_fraction = gsearch3.best_params_['feature_fraction']\\n\\n\\nmodel_lgb = lgb.LGBMClassifier(n_estimators=30,\\n                               silent=True,\\n                               max_bin=best_max_bin,\\n                               learning_rate=0.1,\\n                               num_leaves=best_num_leaves,\\n                               min_data_in_leaf=best_min_data_in_leaf,\\n                               bagging_fraction=best_bagging_fraction,\\n                               feature_fraction=best_feature_fraction,\\n                               max_depth=best_max_depth)\\n\\nparams_test4={'reg_alpha': [0, 0.001, 0.01, 0.03, 0.08, 0.3, 0.5,0.8,1.0], 'reg_lambda': [0.0,0.001, 0.01, 0.03, 0.08, 0.1,0.2,0.3,0.4,0.5,0.8,1.0]}\\ngsearch4 = GridSearchCV(estimator=model_lgb, param_grid=params_test4, scoring='roc_auc', cv=5, verbose=1, n_jobs=8)\\nbest_reg_alpha = gsearch4.best_params_['reg_alpha']\\nbest_reg_lambda = gsearch4.best_params_['reg_lambda']\\n\\n\\nmodel_lgb = lgb.LGBMClassifier(n_estimators=30,\\n                               silent=True,\\n                               max_bin=best_max_bin,\\n                               learning_rate=0.1,\\n                               num_leaves=best_num_leaves,\\n                               min_data_in_leaf=best_min_data_in_leaf,\\n                               bagging_fraction=best_bagging_fraction,\\n                               feature_fraction=best_feature_fraction,\\n                               max_depth=best_max_depth)\\n\\nparams_test0={'n_estimators':range(10,100,5)}\\ngsearch0 = GridSearchCV(estimator=model_lgb, param_grid=params_test0, scoring='roc_auc', cv=5, verbose=1, n_jobs=8)\\n\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "params_test1={'max_depth': range(3,10,1), 'num_leaves':range(5, 100, 5)}\n",
    "gsearch1 = GridSearchCV(estimator=model_lgb, param_grid=params_test1, scoring='roc_auc', cv=5, verbose=1, n_jobs=8)\n",
    "gsearch1.fit(df_X, df_y)\n",
    "best_max_depth = gsearch1.best_params_['max_depth']\n",
    "best_num_leaves = gsearch1.best_params_['num_leaves']\n",
    "\n",
    "\n",
    "model_lgb = lgb.LGBMClassifier(n_estimators=30,\n",
    "                               silent=True,\n",
    "                               max_bin=50,\n",
    "                               learning_rate=0.1,\n",
    "                               num_leaves=best_num_leaves,\n",
    "                               min_data_in_leaf=20,\n",
    "                               feature_fraction=1.0,\n",
    "                               max_depth=best_max_depth)\n",
    "\n",
    "params_test2={'max_bin': range(5,255,5), 'min_data_in_leaf':range(10, 200, 5)}\n",
    "gsearch2 = GridSearchCV(estimator=model_lgb, param_grid=params_test2, scoring='roc_auc', cv=5, verbose=1, n_jobs=8)\n",
    "gsearch2.fit(df_X, df_y)\n",
    "best_max_bin = gsearch2.best_params_['max_bin']\n",
    "best_min_data_in_leaf = gsearch2.best_params_['min_data_in_leaf']\n",
    "\n",
    "\n",
    "\n",
    "model_lgb = lgb.LGBMClassifier(n_estimators=30,\n",
    "                               silent=True,\n",
    "                               max_bin=best_max_bin,\n",
    "                               learning_rate=0.1,\n",
    "                               num_leaves=best_num_leaves,\n",
    "                               min_data_in_leaf=best_min_data_in_leaf,\n",
    "                               feature_fraction=1.0,\n",
    "                               max_depth=best_max_depth)\n",
    "\n",
    "params_test3={'feature_fraction': [0.5, 0.6, 0.7, 0.8, 0.9,1.0], 'bagging_fraction': [0.6, 0.7, 0.8, 0.9, 1.0]}\n",
    "gsearch3 = GridSearchCV(estimator=model_lgb, param_grid=params_test3, scoring='roc_auc', cv=5, verbose=1, n_jobs=8)\n",
    "gsearch3.fit(df_X, df_y)\n",
    "best_bagging_fraction = gsearch3.best_params_['bagging_fraction']\n",
    "best_feature_fraction = gsearch3.best_params_['feature_fraction']\n",
    "\n",
    "\n",
    "model_lgb = lgb.LGBMClassifier(n_estimators=30,\n",
    "                               silent=True,\n",
    "                               max_bin=best_max_bin,\n",
    "                               learning_rate=0.1,\n",
    "                               num_leaves=best_num_leaves,\n",
    "                               min_data_in_leaf=best_min_data_in_leaf,\n",
    "                               bagging_fraction=best_bagging_fraction,\n",
    "                               feature_fraction=best_feature_fraction,\n",
    "                               max_depth=best_max_depth)\n",
    "\n",
    "params_test4={'reg_alpha': [0, 0.001, 0.01, 0.03, 0.08, 0.3, 0.5,0.8,1.0], 'reg_lambda': [0.0,0.001, 0.01, 0.03, 0.08, 0.1,0.2,0.3,0.4,0.5,0.8,1.0]}\n",
    "gsearch4 = GridSearchCV(estimator=model_lgb, param_grid=params_test4, scoring='roc_auc', cv=5, verbose=1, n_jobs=8)\n",
    "best_reg_alpha = gsearch4.best_params_['reg_alpha']\n",
    "best_reg_lambda = gsearch4.best_params_['reg_lambda']\n",
    "\n",
    "\n",
    "model_lgb = lgb.LGBMClassifier(n_estimators=30,\n",
    "                               silent=True,\n",
    "                               max_bin=best_max_bin,\n",
    "                               learning_rate=0.1,\n",
    "                               num_leaves=best_num_leaves,\n",
    "                               min_data_in_leaf=best_min_data_in_leaf,\n",
    "                               bagging_fraction=best_bagging_fraction,\n",
    "                               feature_fraction=best_feature_fraction,\n",
    "                               max_depth=best_max_depth)\n",
    "\n",
    "params_test0={'n_estimators':range(10,100,5)}\n",
    "gsearch0 = GridSearchCV(estimator=model_lgb, param_grid=params_test0, scoring='roc_auc', cv=5, verbose=1, n_jobs=8)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2  train lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['light_gbm_appetency.model']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appetency_gbm = lgb.LGBMClassifier(n_estimators=1800,\n",
    "                               silent=True,\n",
    "                               max_bin=50,\n",
    "                               learning_rate=0.05,\n",
    "                               num_leaves=1023,\n",
    "                               min_data_in_leaf=20,\n",
    "                               feature_fraction=0.8,\n",
    "                               bagging_fraction=1.0,\n",
    "                               max_depth=10,\n",
    "                               reg_alpha = 0.1,\n",
    "                               reg_lambda = 0.2,\n",
    "                               class_weight='balanced'\n",
    "                               )\n",
    "appetency_gbm.fit(df_X_lightgbm_appetency, df_y_lightgbm_appetency)\n",
    "joblib.dump(appetency_gbm,\"light_gbm_appetency.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['light_gbm_churn.model']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_gbm = lgb.LGBMClassifier(n_estimators=1800,\n",
    "                               silent=True,\n",
    "                               max_bin=50,\n",
    "                               learning_rate=0.05,\n",
    "                               num_leaves=255,\n",
    "                               min_data_in_leaf=5,\n",
    "                               feature_fraction=0.8,\n",
    "                               bagging_fraction=1.0,\n",
    "                               max_depth=8,\n",
    "                               reg_alpha = 0.01,\n",
    "                               reg_lambda = 0.1,\n",
    "                               class_weight='balanced'\n",
    "                               )\n",
    "churn_gbm.fit(df_X_lightgbm_churn, df_y_lightgbm_churn)\n",
    "joblib.dump(churn_gbm,\"light_gbm_churn.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['light_gbm_upselling.model']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "upselling_gbm = lgb.LGBMClassifier(n_estimators=1800,\n",
    "                               silent=True,\n",
    "                               max_bin=50,\n",
    "                               learning_rate=0.05,\n",
    "                               num_leaves=511,\n",
    "                               min_data_in_leaf=20,\n",
    "                               feature_fraction=0.8,\n",
    "                               bagging_fraction=1.0,\n",
    "                               max_depth=9,\n",
    "                               reg_alpha = 0.1,\n",
    "                               reg_lambda = 0.2,\n",
    "                               class_weight='balanced'\n",
    "                               )\n",
    "upselling_gbm.fit(df_X_lightgbm_upselling, df_y_lightgbm_upselling)\n",
    "joblib.dump(upselling_gbm,\"light_gbm_upselling.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
